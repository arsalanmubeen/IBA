{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arsalanmubeen/IBA/blob/main/Deep_Learning_Project_Arsalan_Mubeen_and_Rabiya_Owais_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g4Y2C5v2cld"
      },
      "source": [
        "# PROJECT NAME:\n",
        "# Improving quality and Classifying radiology images using 5 types of CNN and a denoising autoencoder\n",
        "# ------------------------------------------------------------------------------------\n",
        "## This project is about analyzing radiology images in healthcare domain; for this project we have used x-ray images dataset which we have recieved from INDUS HOSPITAL for the purposes of analysis and testing. \n",
        "\n",
        "## In this project we aim to do two major deep learning workings; this is an end to end pipeline from data load to CNN training and then classification. \n",
        "## The first part deals with Classification of radiology images using Convolutional Neural Networks to show if the x-ray is normal or abnormal. \n",
        "## This use case would help determine if any disease or infection may exist in the chest which is being detected in the CNN. \n",
        "\n",
        "## The second part of this project uses DAE - denoising autoencoder; the aim of this use case is to show how x-ray image quality can be improved using a DAE. \n",
        "\n",
        "## at the end of this notebook is a detailed analysis of the different parameters, pooling and padding functionality tried in this experiment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMxYSTk5cI2U"
      },
      "source": [
        "# **Analysis**: \n",
        "\n",
        "# In this project we aimed to improve the quality and learning of x-ray images for classification purposes of any abnormality found in the X-ray.\n",
        "\n",
        "## As a comparative analysis, we have used different types of convolutional neural networks such as LeNet, AlexNet, VGGNet and GoogleNet. \n",
        "\n",
        "## We have also made a customised CNN model of our own based on the different results we got from the above types. \n",
        "\n",
        "## For performance measurement, we have used accuracy as a metric to signify how well our models have learned the classification of our dataset. \n",
        "\n",
        "## From this experiment we have seen that the best performance was from the customised CNN model we made with 93% accuracy, 0.19 loss using 10 epochs and 8 steps per training. \n",
        "\n",
        "## LeNet performance was not up to the mark even though we used more epochs and same training steps and a 5 layers CNN. The accuracy came out to be 52%. \n",
        "\n",
        "## AlexNet performance was lower with accuracy of 47% with exponentially increasing loss.\n",
        "\n",
        "## VGGNet around 50%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbkbHJna2cll"
      },
      "source": [
        "### Making necessary imports: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvS0M2dT2clm",
        "outputId": "eac3f04f-a986-47d2-b866-d471a8bf62de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of replicas: 1\n",
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution() \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "    \n",
        "print(tf.__version__)\n",
        "\n",
        "import sys\n",
        "from zipfile import ZipFile\n",
        "import argparse\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from collections import Counter\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import inspect\n",
        "import gc\n",
        "import re\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import models\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, GlobalAveragePooling1D, GlobalAveragePooling2D, Flatten, BatchNormalization, Dense\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.constraints import maxnorm\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD , RMSprop\n",
        "from tensorflow.keras import backend as K\n",
        "#K.set_image_dim_ordering('th')\n",
        "\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import display\n",
        "import seaborn as sns\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASKdY2-U2clq"
      },
      "source": [
        "## Below are the parameter tuning variables that will be needed for analyzing our CNN over different combinations of these parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FF17fVv2clr"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "IMAGE_SIZE = [180, 180]\n",
        "EPOCHS = 25\n",
        "FILE_PATH =\"images/*\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0fsdpdeedS0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7umQrh6WA9v",
        "outputId": "cd741e88-0a6f-49f6-be0e-0c29509381b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLb0AhTDWRUp",
        "outputId": "4cd57450-3e56-4759-9aa7-5a2d15497f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading indussample.zip to /content\n",
            " 88% 105M/120M [00:03<00:00, 31.4MB/s] \n",
            "100% 120M/120M [00:03<00:00, 37.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "#!kaggle datasets download -d arsalanmubeen123/images-indus-hospital\n",
        "!kaggle datasets download -d rabiya1212/indussample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwBDS-R5Xva-"
      },
      "outputs": [],
      "source": [
        "#with ZipFile('images-indus-hospital.zip', 'r') as images_indus_hospital:\n",
        "#  images_indus_hospital.extractall()\n",
        "\n",
        "#os.rename('/content/images', '/content/images-indus-hospital')\n",
        "\n",
        "#! kaggle datasets download paultimothymooney/chest-xray-pneumonia\n",
        "#! unzip chest-xray-pneumonia.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS2tOXYi9vus"
      },
      "outputs": [],
      "source": [
        "with ZipFile('indussample.zip', 'r') as indussample:\n",
        "  indussample.extractall()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qSJ7Nik2cls"
      },
      "source": [
        "## creating a directory to store classified images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a3hU-NX2clt",
        "outputId": "8d90a960-5389-455e-c76a-e87e7349b8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder created successfully\n"
          ]
        }
      ],
      "source": [
        "TARGET = \"/content/Classified images\"\n",
        "\n",
        "if not os.path.exists(TARGET):\n",
        "    os.mkdir(TARGET)\n",
        "    print(\"folder created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM10DC272clu"
      },
      "source": [
        "## Sampling from images available. we wont pick all images as it may disturb the class balance, hence we have used 50% normal images and 50% abnormal or anomoly images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lgtSC2p2clv"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "target = \"target\"\n",
        "indus_image_file = \"/content/training/Normal\" #images-indus-hospital"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2ZgGmnO2clw",
        "outputId": "23ddf263-7da0-4dfb-f6f4-8a49cf05d1df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "image_names = os.listdir(indus_image_file)\n",
        "len(image_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYFgBJz_2clx"
      },
      "source": [
        "## Now we checked the total images we have in the normal dataset folder. We saw using the len(images) function that we have a total of 4999 images in our data set. \n",
        "\n",
        "## to make this problem more generalized, what we now do is that we will randomly sample out some images from these 4999 images. \n",
        "\n",
        "## For this we use the random.shuffle() function which will randomly pick some image names from our overall dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohUYdG3k2clx"
      },
      "outputs": [],
      "source": [
        "random.shuffle(image_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfgWO4Gw2cly"
      },
      "source": [
        "## Next we run a loop to make the random selection; so for instance if we have 4999 images, we will pick say the first 120 images out of the 4999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKngfhMz2cly",
        "outputId": "41c0cb00-369c-4063-a475-8d3936f01342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copied 0 (1024, 1024, 3)\n",
            "copied 1 (1024, 1024, 3)\n",
            "copied 2 (1024, 1024, 3)\n",
            "copied 3 (1024, 1024, 3)\n",
            "copied 4 (1024, 1024, 3)\n",
            "copied 5 (1024, 1024, 3)\n",
            "copied 6 (1024, 1024, 3)\n",
            "copied 7 (1024, 1024, 3)\n",
            "copied 8 (1024, 1024, 3)\n",
            "copied 9 (1024, 1024, 3)\n",
            "copied 10 (1024, 1024, 3)\n",
            "copied 11 (1024, 1024, 3)\n",
            "copied 12 (1024, 1024, 3)\n",
            "copied 13 (1024, 1024, 3)\n",
            "copied 14 (1024, 1024, 3)\n",
            "copied 15 (1024, 1024, 3)\n",
            "copied 16 (1024, 1024, 3)\n",
            "copied 17 (1024, 1024, 3)\n",
            "copied 18 (1024, 1024, 3)\n",
            "copied 19 (1024, 1024, 3)\n",
            "copied 20 (1024, 1024, 3)\n",
            "copied 21 (1024, 1024, 3)\n",
            "copied 22 (1024, 1024, 3)\n",
            "copied 23 (1024, 1024, 3)\n",
            "copied 24 (1024, 1024, 3)\n",
            "copied 25 (1024, 1024, 3)\n",
            "copied 26 (1024, 1024, 3)\n",
            "copied 27 (1024, 1024, 3)\n",
            "copied 28 (1024, 1024, 3)\n",
            "copied 29 (1024, 1024, 3)\n",
            "copied 30 (1024, 1024, 3)\n",
            "copied 31 (1024, 1024, 3)\n",
            "copied 32 (1024, 1024, 3)\n",
            "copied 33 (1024, 1024, 3)\n",
            "copied 34 (1024, 1024, 3)\n",
            "copied 35 (1024, 1024, 3)\n",
            "copied 36 (1024, 1024, 3)\n",
            "copied 37 (1024, 1024, 3)\n",
            "copied 38 (1024, 1024, 3)\n",
            "copied 39 (1024, 1024, 3)\n",
            "copied 40 (1024, 1024, 3)\n",
            "copied 41 (1024, 1024, 3)\n",
            "copied 42 (1024, 1024, 3)\n",
            "copied 43 (1024, 1024, 3)\n",
            "copied 44 (1024, 1024, 3)\n",
            "copied 45 (1024, 1024, 3)\n",
            "copied 46 (1024, 1024, 3)\n",
            "copied 47 (1024, 1024, 3)\n",
            "copied 48 (1024, 1024, 3)\n",
            "copied 49 (1024, 1024, 3)\n",
            "copied 50 (1024, 1024, 3)\n",
            "copied 51 (1024, 1024, 3)\n",
            "copied 52 (1024, 1024, 3)\n",
            "copied 53 (1024, 1024, 3)\n",
            "copied 54 (1024, 1024, 3)\n",
            "copied 55 (1024, 1024, 3)\n",
            "copied 56 (1024, 1024, 3)\n",
            "copied 57 (1024, 1024, 3)\n",
            "copied 58 (1024, 1024, 3)\n",
            "copied 59 (1024, 1024, 3)\n",
            "copied 60 (1024, 1024, 3)\n",
            "copied 61 (1024, 1024, 3)\n",
            "copied 62 (1024, 1024, 3)\n",
            "copied 63 (1024, 1024, 3)\n",
            "copied 64 (1024, 1024, 3)\n",
            "copied 65 (1024, 1024, 3)\n",
            "copied 66 (1024, 1024, 3)\n",
            "copied 67 (1024, 1024, 3)\n",
            "copied 68 (1024, 1024, 3)\n",
            "copied 69 (1024, 1024, 3)\n",
            "copied 70 (1024, 1024, 3)\n",
            "copied 71 (1024, 1024, 3)\n",
            "copied 72 (1024, 1024, 3)\n",
            "copied 73 (1024, 1024, 3)\n",
            "copied 74 (1024, 1024, 3)\n",
            "copied 75 (1024, 1024, 3)\n",
            "copied 76 (1024, 1024, 3)\n",
            "copied 77 (1024, 1024, 3)\n",
            "copied 78 (1024, 1024, 3)\n",
            "copied 79 (1024, 1024, 3)\n",
            "copied 80 (1024, 1024, 3)\n",
            "copied 81 (1024, 1024, 3)\n",
            "copied 82 (1024, 1024, 3)\n",
            "copied 83 (1024, 1024, 3)\n",
            "copied 84 (1024, 1024, 3)\n",
            "copied 85 (1024, 1024, 3)\n",
            "copied 86 (1024, 1024, 3)\n",
            "copied 87 (1024, 1024, 3)\n",
            "copied 88 (1024, 1024, 3)\n",
            "copied 89 (1024, 1024, 3)\n",
            "copied 90 (1024, 1024, 3)\n",
            "copied 91 (1024, 1024, 3)\n",
            "copied 92 (1024, 1024, 3)\n",
            "copied 93 (1024, 1024, 3)\n",
            "copied 94 (1024, 1024, 3)\n",
            "copied 95 (1024, 1024, 3)\n",
            "copied 96 (1024, 1024, 3)\n",
            "copied 97 (1024, 1024, 3)\n",
            "copied 98 (1024, 1024, 3)\n",
            "copied 99 (1024, 1024, 3)\n",
            "copied 100 (1024, 1024, 3)\n",
            "copied 101 (1024, 1024, 3)\n",
            "copied 102 (1024, 1024, 3)\n",
            "copied 103 (1024, 1024, 3)\n",
            "copied 104 (1024, 1024, 3)\n",
            "copied 105 (1024, 1024, 3)\n",
            "copied 106 (1024, 1024, 3)\n",
            "copied 107 (1024, 1024, 3)\n",
            "copied 108 (1024, 1024, 3)\n",
            "copied 109 (1024, 1024, 3)\n",
            "copied 110 (1024, 1024, 3)\n",
            "copied 111 (1024, 1024, 3)\n",
            "copied 112 (1024, 1024, 3)\n",
            "copied 113 (1024, 1024, 3)\n",
            "copied 114 (1024, 1024, 3)\n",
            "copied 115 (1024, 1024, 3)\n",
            "copied 116 (1024, 1024, 3)\n",
            "copied 117 (1024, 1024, 3)\n",
            "copied 118 (1024, 1024, 3)\n",
            "copied 119 (1024, 1024, 3)\n",
            "copied 120 (1024, 1024, 3)\n",
            "copied 121 (1024, 1024, 3)\n",
            "copied 122 (1024, 1024, 3)\n",
            "copied 123 (1024, 1024, 3)\n",
            "copied 124 (1024, 1024, 3)\n",
            "copied 125 (1024, 1024, 3)\n",
            "copied 126 (1024, 1024, 3)\n",
            "copied 127 (1024, 1024, 3)\n",
            "copied 128 (1024, 1024, 3)\n",
            "copied 129 (1024, 1024, 3)\n",
            "copied 130 (1024, 1024, 3)\n",
            "copied 131 (1024, 1024, 3)\n",
            "copied 132 (1024, 1024, 3)\n",
            "copied 133 (1024, 1024, 3)\n",
            "copied 134 (1024, 1024, 3)\n",
            "copied 135 (1024, 1024, 3)\n",
            "copied 136 (1024, 1024, 3)\n",
            "copied 137 (1024, 1024, 3)\n",
            "copied 138 (1024, 1024, 3)\n",
            "copied 139 (1024, 1024, 3)\n",
            "copied 140 (1024, 1024, 3)\n",
            "copied 141 (1024, 1024, 3)\n",
            "copied 142 (1024, 1024, 3)\n",
            "copied 143 (1024, 1024, 3)\n",
            "copied 144 (1024, 1024, 3)\n",
            "copied 145 (1024, 1024, 3)\n",
            "copied 146 (1024, 1024, 3)\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(image_names)): # 200\n",
        "    image_name = image_names[i]\n",
        "    image_path = os.path.join(indus_image_file,image_name)\n",
        "  \n",
        "    target_path = os.path.join(TARGET,image_name)\n",
        "    \n",
        "    im = cv2.imread(image_path)\n",
        "    #originalImage = cv2.imread(image_path)\n",
        "    #grayImage = cv2.cvtColor(originalImage, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    shutil.copy2(image_path,target_path)\n",
        "    print(\"copied\",i,im.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjr9y8kJ2clz"
      },
      "outputs": [],
      "source": [
        "Train = \"/content/training\"\n",
        "Validation = \"/content/val\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l19CchR2clz"
      },
      "source": [
        "## Now we create our initial CNN model:\n",
        "\n",
        "## the model is build using keras and works as a sequential model such that there are multiple layers, with each layer having some number of filters. \n",
        "\n",
        "## we have use a convolutional layer with filter size 32 first. \n",
        "\n",
        "## using a smaller filter size here will help to look at the smaller areas of the overall image pixels and detect the patterns. \n",
        "\n",
        "## this is particularly neccessary in the begininning as we want to capture the anomoly patterns of the x-ray images to see if some issue exists on not. \n",
        "\n",
        "## this will allow it learn a hidden pattern; \n",
        "## later as we will go deeper in the network, the receptive field of the CNN layer will increases. This will allow the model to learn high level features later on in the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hfTIpuZ2cl0"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(Conv2D(64,(3,3),activation='relu',input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "##final layer\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=keras.losses.binary_crossentropy,optimizer='adam',metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygz3fOO2cl0"
      },
      "source": [
        "## For this model, the kernal size is kept as 3x3 which is a standard size used generally for initializing CNNs and the activation function used in the layers is relu in this case. \n",
        "\n",
        "## in the second layer we use a filter size of 64 to get 64 feature selectors this time. \n",
        "\n",
        "## next we have added the pooling layers using the default size. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sx-LeRQ2cl0"
      },
      "source": [
        "## we have also added a droppout layer in our model to deal with any form of overfitting that may occur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYzsmLUz2cl1"
      },
      "source": [
        "## note that as we go deeper in the network we increase the number of filters to 128 as we want more feature maps generated for efficient learning \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97ESRBsw2cl1"
      },
      "source": [
        "## Final layer\n",
        "\n",
        "### for our CNN we have used 1 neuron in the final layer as we are performing binary classification hence we just need one neuron. furthermore we have used sigmoid activation in the final layer because we expect an output as a binary 1 or 0 and the sigmoid function maps the values between this range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98rS7kgl2cl1"
      },
      "source": [
        "## Model Performance Metric: \n",
        "\n",
        "### to measure the performance of our designed model, we have used optimizer as adam (which is basically doing gradient descent) and loss as binary cross entropy loss along with performance metric as accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3MJbMLh2cl2",
        "outputId": "2a41df21-de87-4392-8bb9-9fea46189660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 220, 220, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 110, 110, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 110, 110, 64)      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 108, 108, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 54, 54, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 26, 26, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                5537856   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,668,097\n",
            "Trainable params: 5,668,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7--8liIW2cl2"
      },
      "source": [
        "## Model Training along with Data Augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6rfWXBc2cl2"
      },
      "outputs": [],
      "source": [
        "train_gen = image.ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    shear_range= 0.2,\n",
        "    zoom_range =0.2,\n",
        "    horizontal_flip = True,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = image.ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "3onWbH19zBZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmwGDCYZ2cl3",
        "outputId": "9fe99960-1717-401a-ec09-e43bf2b8d489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 300 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_gen.flow_from_directory(\n",
        "      '/content/training',\n",
        "    target_size = (224, 224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ungUEhEK2cl3",
        "outputId": "50a84be1-536c-455d-e1fe-9a9e8c8deba4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Abnormality': 0, 'Normal': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxmT7JQb2cl3",
        "outputId": "44eab676-15c0-4e10-bc32-1f9790454bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_generator = test_dataset.flow_from_directory(\n",
        "      '/content/val',\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary'\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igJoP_eZ2cl4",
        "outputId": "88282cd5-9af1-45a2-9009-5d2669e1061d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - ETA: 0s - batch: 3.5000 - size: 29.5000 - loss: 0.7656 - accuracy: 0.6653"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 19s 642ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.7675 - accuracy: 0.6653 - val_loss: 0.7254 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 6s 819ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.4941 - accuracy: 0.7585 - val_loss: 0.9349 - val_accuracy: 0.4375\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 8s 998ms/step - batch: 3.5000 - size: 32.0000 - loss: 0.3817 - accuracy: 0.8594 - val_loss: 0.9575 - val_accuracy: 0.4375\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 7s 939ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.2585 - accuracy: 0.9110 - val_loss: 1.4942 - val_accuracy: 0.4375\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 7s 917ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.2705 - accuracy: 0.9153 - val_loss: 1.2505 - val_accuracy: 0.3750\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 7s 925ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.2639 - accuracy: 0.9153 - val_loss: 1.1430 - val_accuracy: 0.3125\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 8s 1s/step - batch: 3.5000 - size: 32.0000 - loss: 0.2660 - accuracy: 0.8789 - val_loss: 1.2738 - val_accuracy: 0.4375\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 9s 1s/step - batch: 3.5000 - size: 29.5000 - loss: 0.1880 - accuracy: 0.9322 - val_loss: 1.7049 - val_accuracy: 0.3750\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 7s 928ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.2493 - accuracy: 0.9195 - val_loss: 1.4771 - val_accuracy: 0.4375\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 7s 914ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.2488 - accuracy: 0.9322 - val_loss: 1.0724 - val_accuracy: 0.4375\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 8,\n",
        "    epochs = 10,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=2\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7LAa3S8jWyg"
      },
      "source": [
        "# **LeNet** **Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRVUqv_3jmkg"
      },
      "source": [
        "LeNet-5 layers:\n",
        "Convolution #1. Input = 224x224x3. Output = 28x28x6 conv2d\n",
        "\n",
        "SubSampling #1. Input = 224x224x6. Output = 14x14x6. SubSampling is simply \n",
        "\n",
        "Average Pooling so we use avg_pool\n",
        "\n",
        "Convolution #2. Input = 14x14x6. Output = 10x10x16 conv2d\n",
        "\n",
        "SubSampling #2. Input = 10x10x16. Output = 5x5x16 avg_pool\n",
        "\n",
        "Fully Connected #1. Input = 5x5x16. Output = 120\n",
        "\n",
        "Fully Connected #2. Input = 120. Output = 84\n",
        "\n",
        "Output 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbgWOF0CjVfM"
      },
      "outputs": [],
      "source": [
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model2.add(layers.AveragePooling2D())\n",
        "\n",
        "model2.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu',input_shape=(224, 224, 3)))\n",
        "model2.add(layers.AveragePooling2D())\n",
        "model2.add(layers.Flatten())\n",
        "\n",
        "model2.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "model2.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model2.add(layers.Dense(units=1, activation = 'softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6x7NVrdkcib",
        "outputId": "c16c50fa-5952-4df2-97ac-2d4a94c64d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 222, 222, 6)       168       \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 111, 111, 6)      0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 109, 109, 16)      880       \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 54, 54, 16)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 46656)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 120)               5598840   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,610,137\n",
            "Trainable params: 5,610,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDs5XGjykkaM"
      },
      "outputs": [],
      "source": [
        "model2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RhryD-ilKWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88385c40-ccc6-4cc8-99fa-935581226f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "6/6 [==============================] - ETA: 0s - batch: 2.5000 - size: 32.0000 - loss: 3.5259 - accuracy: 0.5052"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 8s 1s/step - batch: 2.5000 - size: 32.0000 - loss: 3.5259 - accuracy: 0.5052 - val_loss: 2.6474 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "6/6 [==============================] - 5s 887ms/step - batch: 2.5000 - size: 28.6667 - loss: 1.1316 - accuracy: 0.4535 - val_loss: 1.4950 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "6/6 [==============================] - 5s 937ms/step - batch: 2.5000 - size: 32.0000 - loss: 0.6562 - accuracy: 0.4948 - val_loss: 0.9295 - val_accuracy: 0.5000\n",
            "Epoch 4/15\n",
            "6/6 [==============================] - 5s 836ms/step - batch: 2.5000 - size: 28.6667 - loss: 0.4455 - accuracy: 0.5000 - val_loss: 1.3020 - val_accuracy: 0.5000\n",
            "Epoch 5/15\n",
            "6/6 [==============================] - 5s 823ms/step - batch: 2.5000 - size: 28.6667 - loss: 0.4214 - accuracy: 0.4942 - val_loss: 1.0160 - val_accuracy: 0.5000\n",
            "Epoch 6/15\n",
            "6/6 [==============================] - 5s 926ms/step - batch: 2.5000 - size: 32.0000 - loss: 0.2402 - accuracy: 0.5208 - val_loss: 1.7426 - val_accuracy: 0.5000\n",
            "Epoch 7/15\n",
            "6/6 [==============================] - 4s 811ms/step - batch: 2.5000 - size: 25.3333 - loss: 0.2587 - accuracy: 0.4211 - val_loss: 1.2370 - val_accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "6/6 [==============================] - 5s 932ms/step - batch: 2.5000 - size: 32.0000 - loss: 0.2556 - accuracy: 0.5000 - val_loss: 1.6280 - val_accuracy: 0.5000\n",
            "Epoch 9/15\n",
            "6/6 [==============================] - 5s 834ms/step - batch: 2.5000 - size: 28.6667 - loss: 0.1658 - accuracy: 0.4826 - val_loss: 1.6017 - val_accuracy: 0.5000\n",
            "Epoch 10/15\n",
            "6/6 [==============================] - 5s 931ms/step - batch: 2.5000 - size: 32.0000 - loss: 0.1944 - accuracy: 0.5104 - val_loss: 2.4290 - val_accuracy: 0.5000\n",
            "Epoch 11/15\n",
            "6/6 [==============================] - 5s 886ms/step - batch: 2.5000 - size: 28.6667 - loss: 0.1718 - accuracy: 0.4942 - val_loss: 2.0272 - val_accuracy: 0.5000\n",
            "Epoch 12/15\n",
            "6/6 [==============================] - 5s 944ms/step - batch: 2.5000 - size: 32.0000 - loss: 0.1461 - accuracy: 0.4740 - val_loss: 2.4815 - val_accuracy: 0.5000\n",
            "Epoch 13/15\n",
            "6/6 [==============================] - 4s 823ms/step - batch: 2.5000 - size: 28.6667 - loss: 0.1826 - accuracy: 0.5000 - val_loss: 2.2040 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "6/6 [==============================] - 5s 946ms/step - batch: 2.5000 - size: 32.0000 - loss: 0.1181 - accuracy: 0.4896 - val_loss: 2.7958 - val_accuracy: 0.5000\n",
            "Epoch 15/15\n",
            "6/6 [==============================] - 4s 815ms/step - batch: 2.5000 - size: 28.6667 - loss: 0.1586 - accuracy: 0.4942 - val_loss: 2.4440 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "hist = model2.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 6,\n",
        "    epochs = 15,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=2\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rznHrl6StVtW"
      },
      "source": [
        "#**AlexNet**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4Tztd0JoVGd",
        "outputId": "be994f0c-45bc-405b-81a0-a1967377f1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 56, 56, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 56, 56, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 28, 28, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 28, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 14, 14, 384)       885120    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 14, 14, 384)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 14, 14, 384)       1327488   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 14, 14, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 14, 14, 384)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 256)       884992    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 14, 14, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 14, 14, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4096)              51384320  \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 4096)             16384     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 4096)             16384     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1000)              4097000   \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 1000)             4000      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 1000)              0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 1001      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 1)                4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76,053,109\n",
            "Trainable params: 76,031,971\n",
            "Non-trainable params: 21,138\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiation\n",
        "AlexNet = Sequential()\n",
        "\n",
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, input_shape=(224,224,3), kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384,input_shape=(224,224,3), kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384,input_shape=(224,224,3), kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, input_shape=(224,224,3), kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(224,224,3,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(1))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "\n",
        "#Model Summary\n",
        "AlexNet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9aXCcxluG9Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compiling the model\n",
        "AlexNet.compile(loss = 'binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLFlO5Tix3UF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa34384-0512-48eb-af9a-020a1e23c159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "8/8 [==============================] - ETA: 0s - batch: 3.5000 - size: 29.5000 - loss: 0.4365 - accuracy: 0.4873"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 17s 786ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.4370 - accuracy: 0.4873 - val_loss: 4.1956 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 8s 1s/step - batch: 3.5000 - size: 29.5000 - loss: 0.3596 - accuracy: 0.5127 - val_loss: 2.2471 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 7s 887ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3429 - accuracy: 0.4703 - val_loss: 3.3870 - val_accuracy: 0.5000\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 8s 1s/step - batch: 3.5000 - size: 32.0000 - loss: 0.3391 - accuracy: 0.4961 - val_loss: 0.7628 - val_accuracy: 0.5000\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 7s 900ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3359 - accuracy: 0.4831 - val_loss: 1.3002 - val_accuracy: 0.5000\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 7s 888ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3389 - accuracy: 0.4915 - val_loss: 0.8744 - val_accuracy: 0.5000\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 7s 918ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3371 - accuracy: 0.4915 - val_loss: 0.7859 - val_accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 7s 969ms/step - batch: 3.5000 - size: 32.0000 - loss: 0.3182 - accuracy: 0.4688 - val_loss: 1.1006 - val_accuracy: 0.5000\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 7s 905ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3408 - accuracy: 0.4831 - val_loss: 0.9380 - val_accuracy: 0.5000\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 7s 915ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3261 - accuracy: 0.5169 - val_loss: 2.0412 - val_accuracy: 0.5000\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 6s 869ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3088 - accuracy: 0.4831 - val_loss: 1.1341 - val_accuracy: 0.5000\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 7s 879ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3146 - accuracy: 0.5254 - val_loss: 1.0095 - val_accuracy: 0.5000\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 7s 978ms/step - batch: 3.5000 - size: 32.0000 - loss: 0.3303 - accuracy: 0.4727 - val_loss: 0.9676 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 6s 872ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3022 - accuracy: 0.4746 - val_loss: 0.8432 - val_accuracy: 0.5000\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 7s 863ms/step - batch: 3.5000 - size: 29.5000 - loss: 0.3035 - accuracy: 0.4958 - val_loss: 0.9451 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "hist = AlexNet.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 8,\n",
        "    epochs = 15,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=2\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ar1dA1fy5ub"
      },
      "source": [
        "# **VGG 16**. **Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTNUUFpHy30s",
        "outputId": "fc3b8f24-7efa-4400-eee6-b4cb8918f7c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 112, 112, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 14, 14, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 7, 7, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg16 = Sequential()\n",
        "vgg16.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vgg16.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vgg16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "vgg16.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN1T9W-l1Exs",
        "outputId": "d3fc8c62-a2d9-4fec-b08f-b8d50d8e61d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "vgg16.add(Flatten())\n",
        "vgg16.add(Dense(units=4096,activation=\"relu\"))\n",
        "vgg16.add(Dense(units=4096,activation=\"relu\"))\n",
        "vgg16.add(Dense(units=1, activation=\"softmax\"))\n",
        "opt = Adam(lr=0.001)\n",
        "vgg16.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy']) #'binary_crossentropy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_kBErH91hmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a119d7fc-0452-489a-80ca-2aa74d47bc2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - ETA: 0s - batch: 2.0000 - size: 32.0000 - loss: 0.7475 - accuracy: 0.5500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 32s 2s/step - batch: 2.0000 - size: 32.0000 - loss: 0.7475 - accuracy: 0.5500 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 10s 2s/step - batch: 2.0000 - size: 28.0000 - loss: 0.7046 - accuracy: 0.4214 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 6s 1s/step - batch: 2.0000 - size: 32.0000 - loss: 0.6927 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 5s 1s/step - batch: 2.0000 - size: 28.0000 - loss: 0.6936 - accuracy: 0.4571 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 6s 1s/step - batch: 2.0000 - size: 32.0000 - loss: 0.6945 - accuracy: 0.5125 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 5s 1s/step - batch: 2.0000 - size: 28.0000 - loss: 0.6920 - accuracy: 0.4643 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 6s 1s/step - batch: 2.0000 - size: 32.0000 - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 5s 1s/step - batch: 2.0000 - size: 28.0000 - loss: 0.6928 - accuracy: 0.4786 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 6s 1s/step - batch: 2.0000 - size: 32.0000 - loss: 0.6912 - accuracy: 0.4563 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 5s 1s/step - batch: 2.0000 - size: 28.0000 - loss: 0.6961 - accuracy: 0.5286 - val_loss: 0.6938 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "hist = vgg16.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 5,\n",
        "    epochs = 10,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=2\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiEj6Y8F22_L"
      },
      "source": [
        "# **Google Inception Network Implementation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2ZW7w-i2yj0"
      },
      "outputs": [],
      "source": [
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    \n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
        "\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
        "\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "    \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS0JoXq44LSp"
      },
      "outputs": [],
      "source": [
        "kernel_init = keras.initializers.glorot_uniform()\n",
        "bias_init = keras.initializers.Constant(value=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqngPTTm4sLG",
        "outputId": "a087af04-f78d-4064-989a-664d70c5c159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 224, 224, 96  384         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 224, 224, 16  64          ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 224, 224, 3)  0          ['input_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 224, 224, 64  256         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 224, 224, 12  110720      ['conv2d_25[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 224, 224, 32  12832       ['conv2d_27[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 224, 224, 32  128         ['max_pooling2d_11[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 224, 224, 25  0           ['conv2d_24[0][0]',              \n",
            "                                6)                                'conv2d_26[0][0]',              \n",
            "                                                                  'conv2d_28[0][0]',              \n",
            "                                                                  'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 224, 224, 12  32896       ['concatenate[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 224, 224, 32  8224        ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 224, 224, 25  0          ['concatenate[0][0]']            \n",
            " )                              6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 224, 224, 12  32896       ['concatenate[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 224, 224, 19  221376      ['conv2d_31[0][0]']              \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 224, 224, 96  76896       ['conv2d_33[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 224, 224, 64  16448       ['max_pooling2d_12[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 224, 224, 48  0           ['conv2d_30[0][0]',              \n",
            "                                0)                                'conv2d_32[0][0]',              \n",
            "                                                                  'conv2d_34[0][0]',              \n",
            "                                                                  'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 513,120\n",
            "Trainable params: 513,120\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# function for creating a projected inception module\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
        "\t# 1x1 conv\n",
        "\tconv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\t# 3x3 conv\n",
        "\tconv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
        "\t# 5x5 conv\n",
        "\tconv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
        "\t# 3x3 max pooling\n",
        "\tpool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
        "\tpool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
        " \n",
        "\t# concatenate filters, assumes filters/channels last\n",
        "\tlayer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
        "\treturn layer_out\n",
        " \n",
        " \n",
        "# define model input\n",
        "visible = Input(shape=(224, 224, 3))\n",
        "# add inception block 1\n",
        "layer = inception_module(visible, 64, 96, 128, 16, 32, 32)\n",
        "# add inception block 1\n",
        "layer = inception_module(layer, 128, 128, 192, 32, 96, 64)\n",
        "# create model\n",
        "model = Model(inputs=visible, outputs=layer)\n",
        "\n",
        "# summarize model\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_E3oPbP7uRn"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPool2D,  \\\n",
        "    Dropout, Dense, Input, concatenate,      \\\n",
        "    GlobalAveragePooling2D, AveragePooling2D,\\\n",
        "    Flatten\n",
        "\n",
        "import cv2 \n",
        "import numpy as np \n",
        "from tensorflow.keras.datasets import cifar10 \n",
        "from keras import backend as K \n",
        "import math \n",
        "from tensorflow.keras.optimizers import SGD \n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "\n",
        "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
        "x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
        "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=64,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=128,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_5x5=32,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_3a')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=128,\n",
        "                     filters_3x3_reduce=128,\n",
        "                     filters_3x3=192,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=96,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_3b')\n",
        "\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=192,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=208,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_5x5=48,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4a')\n",
        "\n",
        "\n",
        "x1 = AveragePooling2D((5, 5), strides=3)(x)\n",
        "x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
        "x1 = Flatten()(x1)\n",
        "x1 = Dense(1024, activation='relu')(x1)\n",
        "x1 = Dropout(0.7)(x1)\n",
        "x1 = Dense(10, activation='softmax', name='auxilliary_output_1')(x1)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=160,\n",
        "                     filters_3x3_reduce=112,\n",
        "                     filters_3x3=224,\n",
        "                     filters_5x5_reduce=24,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4b')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=128,\n",
        "                     filters_3x3_reduce=128,\n",
        "                     filters_3x3=256,\n",
        "                     filters_5x5_reduce=24,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4c')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=112,\n",
        "                     filters_3x3_reduce=144,\n",
        "                     filters_3x3=288,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4d')\n",
        "\n",
        "\n",
        "x2 = AveragePooling2D((5, 5), strides=3)(x)\n",
        "x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
        "x2 = Flatten()(x2)\n",
        "x2 = Dense(1024, activation='relu')(x2)\n",
        "x2 = Dropout(0.7)(x2)\n",
        "x2 = Dense(10, activation='softmax', name='auxilliary_output_2')(x2)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=256,\n",
        "                     filters_3x3_reduce=160,\n",
        "                     filters_3x3=320,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_4e')\n",
        "\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=256,\n",
        "                     filters_3x3_reduce=160,\n",
        "                     filters_3x3=320,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_5a')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=384,\n",
        "                     filters_3x3_reduce=192,\n",
        "                     filters_3x3=384,\n",
        "                     filters_5x5_reduce=48,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_5b')\n",
        "\n",
        "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Dense(1, activation='softmax', name='output')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIEaF-3U9hmb",
        "outputId": "68f49e47-ef92-4fce-e541-19ec6b0f4977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "epochs = 25\n",
        "initial_lrate = 0.01\n",
        "\n",
        "def decay(epoch, steps=100):\n",
        "    initial_lrate = 0.01\n",
        "    drop = 0.96\n",
        "    epochs_drop = 8\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "sgd = SGD(lr=initial_lrate, momentum=0.9, nesterov=False)\n",
        "\n",
        "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
        "\n",
        "model.compile(loss=['categorical_crossentropy'], loss_weights=[1], optimizer=sgd, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m34XVACc-YUH",
        "outputId": "2e2197d9-25fb-4ea2-b0d2-6492bd95cd80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 224, 224, 96  384         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 224, 224, 16  64          ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 224, 224, 3)  0          ['input_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 224, 224, 64  256         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 224, 224, 12  110720      ['conv2d_25[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 224, 224, 32  12832       ['conv2d_27[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 224, 224, 32  128         ['max_pooling2d_11[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 224, 224, 25  0           ['conv2d_24[0][0]',              \n",
            "                                6)                                'conv2d_26[0][0]',              \n",
            "                                                                  'conv2d_28[0][0]',              \n",
            "                                                                  'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 224, 224, 12  32896       ['concatenate[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 224, 224, 32  8224        ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 224, 224, 25  0          ['concatenate[0][0]']            \n",
            " )                              6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 224, 224, 12  32896       ['concatenate[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 224, 224, 19  221376      ['conv2d_31[0][0]']              \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 224, 224, 96  76896       ['conv2d_33[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 224, 224, 64  16448       ['max_pooling2d_12[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 224, 224, 48  0           ['conv2d_30[0][0]',              \n",
            "                                0)                                'conv2d_32[0][0]',              \n",
            "                                                                  'conv2d_34[0][0]',              \n",
            "                                                                  'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 513,120\n",
            "Trainable params: 513,120\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 5,\n",
        "    epochs = 10,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=2\n",
        "    \n",
        ")"
      ],
      "metadata": {
        "id": "sU38Ra9Hm-cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv50N-q-2cl4"
      },
      "source": [
        "# Second Part: Denoising images using denoising auto-encoders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDHnn6Ym2cl4"
      },
      "outputs": [],
      "source": [
        "import numpy \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "import numpy as np\n",
        "from pylab import rcParams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIoUvpZyha_8"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\"\"\"\n",
        "This callback will stop the training when there is no improvement in the validation accuracy across epochs\n",
        "\"\"\"\n",
        "early_callback = EarlyStopping(monitor='val_auc', \n",
        "                               verbose=1,\n",
        "                               patience=10,\n",
        "                               mode='max',\n",
        "                               restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHPxgiLG2cl4"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = next(train_generator),next(validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.image_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdSSVRYnXyr1",
        "outputId": "3be9b045-5f0d-4680-fdce-2159afe59d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0]*3, 28, 28))\n",
        "X_test = X_test.reshape((X_test.shape[0]*3, 28, 28))"
      ],
      "metadata": {
        "id": "Z_p3KWcXefCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bWi8jxRC3_e"
      },
      "outputs": [],
      "source": [
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dM-04iLe8d8",
        "outputId": "b9b167ec-ccb0-45d2-d2f0-701067ca191a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psj7r3URkJto"
      },
      "outputs": [],
      "source": [
        "# creating the noise matrix\n",
        "n_rows = X_test.shape[0]\n",
        "n_cols = X_test.shape[1]\n",
        "mean = 0.5\n",
        "stddev = 0.3\n",
        "noise = np.random.normal(mean, stddev, (n_rows, n_cols))\n",
        "# creating the noisy test data by adding X_test with noise\n",
        "X_test_noisy = X_test + noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMw0r6x0muj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce77a18d-358c-451c-eb7b-66e0a0479e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/adagrad.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ],
      "source": [
        "# Deciding how many nodes each layer should have\n",
        "n_nodes_inpl = 784  #encoder\n",
        "n_nodes_hl1  = 32  #encoder\n",
        "n_nodes_hl2  = 32  #decoder\n",
        "n_nodes_outl = 784  #decoder\n",
        "# first hidden layer has 784*32 weights and 32 biases\n",
        "hidden_1_layer_vals = {\n",
        "'weights':tf.Variable(tf.random.normal([n_nodes_inpl,n_nodes_hl1])),\n",
        "'biases':tf.Variable(tf.random.normal([n_nodes_hl1]))  }\n",
        "# second hidden layer has 32*32 weights and 32 biases\n",
        "hidden_2_layer_vals = {\n",
        "'weights':tf.Variable(tf.random.normal([n_nodes_hl1, n_nodes_hl2])),\n",
        "'biases':tf.Variable(tf.random.normal([n_nodes_hl2]))  }\n",
        "# second hidden layer has 32*784 weights and 784 biases\n",
        "output_layer_vals = {\n",
        "'weights':tf.Variable(tf.random.normal([n_nodes_hl2,n_nodes_outl])),'biases':tf.Variable(tf.random.normal([n_nodes_outl])) }\n",
        "# image with shape 784 goes in\n",
        "input_layer = tf.compat.v1.placeholder('float', [None, 784])\n",
        "# multiply output of input_layer wth a weight matrix and add biases\n",
        "layer_1 = tf.nn.sigmoid(\n",
        "       tf.add(tf.matmul(input_layer,hidden_1_layer_vals['weights']),\n",
        "       hidden_1_layer_vals['biases']))\n",
        "# multiply output of layer_1 wth a weight matrix and add biases\n",
        "layer_2 = tf.nn.sigmoid(\n",
        "       tf.add(tf.matmul(layer_1,hidden_2_layer_vals['weights']),\n",
        "       hidden_2_layer_vals['biases']))\n",
        "# multiply output of layer_2 wth a weight matrix and add biases\n",
        "output_layer = tf.matmul(layer_2,output_layer_vals['weights']) +  output_layer_vals['biases']\n",
        "# output_true shall have the original image for error calculations\n",
        "output_true = tf.compat.v1.placeholder('float', [None, 784])\n",
        "# define our cost function\n",
        "meansq =    tf.reduce_mean(tf.square(output_layer - output_true))\n",
        "# define our optimizer\n",
        "learn_rate = 0.1   # how fast the model should learn\n",
        "optimizer = tf.compat.v1.train.AdagradOptimizer(learn_rate).minimize(meansq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu65OdmO2cl8"
      },
      "outputs": [],
      "source": [
        "# initialising stuff and starting the session\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)\n",
        "# defining batch size, number of epochs and learning rate\n",
        "batch_size = 100  # how many images to use together for training\n",
        "hm_epochs =1000    # how many times to go through the entire dataset\n",
        "tot_images = X_train.shape[0] # total number of images\n",
        "\n",
        "# running the model for a 10000 epochs taking 100 images in batches\n",
        "# total improvement is printed out after each epoch\n",
        "for epoch in range(hm_epochs):\n",
        "    epoch_loss = 0    # initializing error as 0\n",
        "    for i in range(int(tot_images/batch_size)):\n",
        "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
        "        _, c = sess.run([optimizer, meansq],feed_dict={input_layer: epoch_x,  output_true: epoch_x})\n",
        "        epoch_loss += c\n",
        "        print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deciding how big we want our print out to be\n",
        "rcParams['figure.figsize'] = 20,20\n",
        "# looping through the first 10 test images and printing  them out\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(X_test[i].reshape(28,28),  cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "# printing out the noisy images\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(X_test_noisy[i].reshape(28,28),  cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "wiZkbU_j55ad",
        "outputId": "b7846493-669c-4971-9ed3-55f63ddcd29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dZ7QV5dnG8Rs1iIIeOhwpwkGq9CIggorSVWxgDAgIgmCP3QiSKESiiRpbVJQmuKLSUUClHRQOvfciSpFDExASNbb3w7veWbN5mWf+T9jCKNfv0yz2NbPPOew9M3uv577vPD/99NNPJiIiIiIiIiIiJ9wpJ/oHEBERERERERGR/6UvakREREREREREEkJf1IiIiIiIiIiIJIS+qBERERERERERSQh9USMiIiIiIiIikhCnuR6cPn06OkiTJk1Q7tRTT0U5M7Pf/OY3OHsiLFiwAOVGjBiBj/nZZ58F2++9957vjxSpb9++kY/t2rULHWPRokUo98UXX6Bcnjx5UO67775DOTOzAgUKoNxNN92EcvRn3L17d+Rjr776KjpGnBtvvDHY7tmzJ95vzJgxKFevXj2UW7p0Kcr98MMPKHfNNdegXNOmTVHOzCxfvnw4m1T/+c9/UO7f//43PuZbb72FciVKlEC5PXv2oBy9PlSoUAHlzjjjDJQzM/vqq6+C7YyMDLyfy4ABAyIf+/TTT9ExNm/ejHJbt25FOXq9/PLLL1HOzOycc85BOdffI2zhwoUo17p168jH6GuJaNGiRbBdtGhRvN/vf/97lDvzzDNRLnzdd2nUqBHK+fwuv3T79u1DuVmzZqHc+++/j5+bnnu///57lKP3L/Q+etq0aSjnc48VPs98/vnneL84HTt2jHxs06ZN6Biu+7CwH3/8EeW+/fZblMubNy/KmfF7k3LlyqEcfa+fddZZkY8NGTIEHSNO48aNg+0yZcrg/bKyslDu66+/RrkrrrgC5caOHYty1atXR7l27dqhnBn//z0RwvdMLocPH0Y512vvSPQcSD+bnSg+w7R37twZbEfdc2lFjYiIiIiIiIhIQuiLGhERERERERGRhMjzk2ONjmsJGS2Zocs+aanEN998g3I+pVOnnMK+r6LLFunS1PBSwSM9++yz6BjErbfeGmzT0iQzs71796btZzDjy5Tr1q2LcoULF07r8czMLrnkEpSbMmUKyt155534uV3osk+6jHXSpEn4uStVqoRy9evXR7lzzz0X5VavXo1y9DVNl9iapZYjPP7443i/OAcPHox8bNWqVegYgwcPRrl169ahHD2n0nO0mVnlypVRjr7fLr30UpRzLSnOnz8/OkacOXPmBNvhZatxtm3bhnJz585FuU6dOqEcXZKd9HLjXxP6f/zkk0+iHC2zys3NRbnt27ejHC0PMUv9GTds2ID3c3FdSw4dOpSW5/g/dLk9LVulpQNmZiVLlkQ5eo9apEgRlKtWrVrkYz5l/XG6d+8ebPuch2j5Fb1HcP2+YVWqVEG5hg0bohwt+zUzO++881COfq5JF/p++/DDD1EuJycHP/dppzm7eAQuu+wylKNl3bTsjZZdz5s3D+XMUu8nXnvtNbxfHNd7hf6f0LJp+j0CfR9t3LgR5cx4SSUtca1duzbKuVoLVKxY8aj/rhU1IiIiIiIiIiIJoS9qREREREREREQSQl/UiIiIiIiIiIgkhLNHTXgMZbiGNE6NGjWO7af6BaK9eGjdaDrrS2mvD9qr4qWXXsLP7VNnStBRknQkHB336lM3Ha5BfPjhh/F+Lo899ljkY7SfwLJly1COjhj+OUbk0bGF9P1WvHhxlHO99sM9SY7Vv/71r2DbZ7Q2HatMexmtX78e5Whfqd/+9rco5zMim/b6OpnQ/hezZ89GuezsbJSbOnUqytFR3T5jwsOvwTvuuAPvF8fVe4ue2+g106cfCeEz/pP2DqPnVNrfpGDBgpGP0T5bcbp06RJs0z4VZvz/rWbNmihHe6AcOHAA5Zo3b45ytH+cmdkFF1yAcj5/x3Sh1y3aE8ynf87IkSNR7sYbb0Q52p8jfC/gQvvw+PRkWrhwYbBNPx/E6dWrV+RjW7ZsQcfYsWMHytHzqc89FkXvS+hnuNNPPx3lXOdTem9PhPu8+IxZp/2xKPp/R/sJ7d+/H+Xo/4cZf12XLVsW5aJGwWtFjYiIiIiIiIhIQuiLGhERERERERGRhHCWPtElRXQZKR0hacbHntESl3Sjo72GDRuGjxkeCUyXYxKDBg2KfIwu3Vq7di3KrVixAuXoEn6fErDzzz8f5cqXL49ytNzJ9Rp8+eWX0THihEu0rr76arwfXfY+a9YslFu8eDHK0b8xHWl38803o5zZ8R9L+XP48ccfUc5naS9dnk9HBxcuXBjl6GjZQoUKoZzPEu/wNYeOVI3z4osvRj5G/3b0NfrJJ5+g3FdffYVyPiWc9D3crFkzlKPnZ9d9QocOHdAxiJ49ewbb9Gcz46N06RjdGTNmoFznzp1Rzqe88JeOltDRsbcffPABfm46YpyW0dEy3TPOOAPl6DVk1KhRKGeWeq9Dy5AI1/uPlovRckBaNpPuEhczswIFCqQ1R8/nUSUVZun7rBG+l/M5B9G2GrSlBn0P0xL/OnXqoFzr1q1RzswsKysLZ483ek6l7yP6Wjbj3xHQc6BPiTDxww8/oFxubi4+ZrgkS6VPIiIiIiIiIiIJpy9qREREREREREQSQl/UiIiIiIiIiIgkhLNHjasmmvYJ2LVrF8rR2i86OvDbb79FOTNei0qfm9ZSumqS6ZhT4rbbbgu2ad8hM94fgY5loz0PSpcujXJt2rRBOZ/eFLR2tF+/fij3/PPP4+d2ob1Ihg4dinKuPhtHeu6551COjpGkY2DpONHly5ejnM8Iw3C/qEmTJuH94qxbty7ysQULFqBjhMcnuoR/Bxfaa4b2CjAzq1ixIsq5Rk6GnXvuuSiXP3/+yMfoyNs47777brC9detWvN+2bdtQbvPmzShHz3+usalhJ2Is78kqJycH5caNG4dyM2fORDk6opTW9tNzuZnZd999F2zTfllxMjMzIx+j/TvomOTwz+/iOgeF+dyj0j4PtHcDPZ+6zkX0PEWEP2vQn83M7ODBg2nN0d6JxYoVQ7l27dqhnM+YdXqPSnsjpQt9H9E+bj69cy6//HKUo/+/6e6BQu/Z6DnGLPUzeLo+Z5iZrVq1KvIx+jmE9pqhfb7ovQk9nhn/W1euXBnl6HvY1dM06tynFTUiIiIiIiIiIgmhL2pERERERERERBLCWfrUt2/fYDudpTgnGh0nTpfJmfElcHRkIh1VS2zfvh3l6NJFn3GOEydORDlaFtC2bVuU27FjB8oVKVIE5VzjDY8ULgEaMmQI3s/lyiuvjHyMjsnbu3cvytHXC33N07JGM172Rpem0rJG1/PS8gMiPIrXp9SELjl1LasMoyU7efPmRblLL70U5XzOa8d76fYvAb0mvfXWWyg3fPhwlCtVqhTK0XMCLbczS30P0zJM4pxzzol8jF6n6XuYjjyl5TCnn346ypmZNWzYMK3HpCVFrtLuN954Ax0jTnhUOh1vbcbHsbteI2E+1ziClmv7lHXXr18f5U7Eeffrr79GuaVLl6LclClT8HN/+OGHKEdLZ8OvSRc6wpfet9F7IrPUMuvp06fj/VzuuuuuyMfo7+AqDQ+jZd2UzxhnWvZGzwn0ns11fp4/fz46BhH+/OJzv0ZbYNAS+nCJuUt4LLzLKaewdSn/bTmvC722NmnS5Kj/rhU1IiIiIiIiIiIJoS9qREREREREREQSwln6NGHCBHQQumysaNGi7Kcys4yMDJSjywxpF2qKLjXzWaL3/vvvB9sjRozw/ZEide/ePfIxupT+448/Rjm6xJEur6UTFMz40s/evXujHJ1Y5iqzeuedd9Ax4lxzzTXBdosWLfB+dEkx/dstWbIE5ej/b8uWLVGuQ4cOKHeyof+/Zma7d+9GuQ8++ADlaKlktWrVUI6WY9HyOLPUJfDpmoxwzz33RD5GSy7p/xu9ztD3Ly3pMePXdTq567777kO5smXLRj5Gp3sQPXr0CLZpCayZ2YMPPohydAk1nSp3ww03oNzZZ5+Ncr8GX331Fcq5JpmEjR49Gj83LWfbt28fytHXCy2DpSUa9DxuljphMV2Tu8zMLrvsssjH6KRSWoZAr4O0XMFnehf9XEOfm563XBNX33zzTXSMOOESS1oeaWZ28803oxyd3NW0aVOUe+GFF1DO9doMu+SSS1DOzG+y2fG2fv16lKP3B7S0y4yXEtP7HXquLFmyJMrRtil0KrZZ6s+oqU8iIiIiIiIiIgmnL2pERERERERERBJCX9SIiIiIiIiIiCSEs0dNly5dInekdZk7d+5EOVrTSGvsfWrEaN2oTx07ER5/fqSaNWum7Xk6duwYbPvU027YsAHl6P8dHVdHR2e6ekWE+dTsV6xYEeVoH4+rrroKP7cLrSN/7bXXUG78+PH4uV3ngTDav4bWttMx4T/H+MpwzWp4pPaxco2wrFy5MjoGfQ9v2rQJ5SpVqoRy27ZtQzkz3vuK1gbTHhOuPmi0Jj3OtGnTgu1PP/0U70f/3+gIWjput1evXijnMy5ejk34NeQyatQolFu2bNmx/Dj/D+3PRvuCmKW+/mlvmTiu8dn0HJQ3b16Uo++Pw4cPo5zP365EiRIoR3tf0Xsx1zVzy5Yt6BjETTfdFGz79DehaF8aOjL7oosuQrlLL70U5WrUqIFyZu5+M2HHe8w67QdCz30FChQ4lh/nqBYvXpzWHO0rRXub+PQcDPcxmjx5Mt4vTng895Ho53nav2bNmjUo165dO5Sj/azMzN577z2Uo9cHeh/tumbVq1fvqP+uFTUiIiIiIiIiIgmhL2pERERERERERBLCWfq0YsWKYDudpTi+6BJRumyMlkrQcXBmfFksXf5Ol7UTdDknXY785JNP4udet25dWnN0HHu43MuFLo/euHEjypmZlSlTJtgeMGAA3s+lefPmkY/RJad0+S8tG6RliHTpoBkfvUxH/tERqoUKFYp8bObMmegYxJ133hls+4xopMsqN2/ejHK0DIw+b926dVGOjnKWo6Ov55EjR6LcsGHDUK5FixYoR0cC0/GzZqmlJI888gjeL46rJJYuac+XLx/K0es+vR7lz58f5cx4OS8t2aHnfdf/cfje8liEy0AaNGiA96NlFfR6RMt5y5Urh3KFCxdGuQsuuADlzMyqV6+OcvQ1nU60tJuWeMyfPx8/Ny1zof8ntNTeVaYbRq+trpKVI02YMCHYzsnJwfu5tG3bNvIxet2iJTO0NNPnMxxVvHhxlKOfW+k109V6I52lT+H3Q2ZmJt5v3LhxKEc/r9B7Dno8n7Iyin6mysrKQrnwiPswragREREREREREUkIfVEjIiIiIiIiIpIQ+qJGRERERERERCQhnD1qXnnlFXQQWi9Na/HMeJ0nrTs788wzUe6zzz5DOVpL7jMmPNwH5e9//zveL45rDDgduUt7XyxcuBDlTj31VJSjvUjMeA3xKaew7ydbtmyJcq6+G/3790fHiBMe80jHkpvxevMxY8agHO1tsnLlSpS79957Ue6KK65AuZONz4jXffv2oRztx0RHU9Pz/urVq1HOZ0x4uMfEgw8+iPdzcfXomjhxIjoG7fOxdu1alKPnU9oDwMysatWqKEd7UNHx83fccUfkY+nslRc+Fr0/MDO7/vrrUa59+/YoN2nSJJTr3bs3yvn8Lr90tLcJva/75z//iZ+b9vTbsGEDytERvvSaTkdw03s7s9TzaXZ2Nt4vTuPGjSMfo/f4Bw4cQDnaL4WeU33eb7Q3Fx1RTu/HunXrFvmYz/2kS7hHDe3jYmbWunVrlKO9hDIyMlDO52ck6O9hZla2bNm0Pnc6LViwAOVoX1afMev0czXtQXXxxRejHP0Og75/6bnXLPUer1mzZkfNaEWNiIiIiIiIiEhC6IsaEREREREREZGEcJY+3X333ZE70rFUdDkiLRGiy6zpOEyz9C8Vdo2pC6tSpUrkY23atEnXj2N/+tOfgm06BtuMlwitWbMG5ejysj59+qAcHU3pMx76nHPOQTm6NDVd6Ai6f/zjHyhHl2Ob8VIYutyPvtdpqQ4t//Ep+8iTJ0+wTUevEk899VTkY7RskC53pjm6BJiWGZiZ7dy5E+XosvbatWujnKsc4ZlnnkHHiBMeLTx69Gi8X9Sy1iPREoh58+ahnKv0NexEjOU9WT399NMoR8ui6LWVnsvpWFufJd7h8+/+/fvxfi6upe07duxAx6D3B/T9kZubi3I+I+rpPSq9xpUoUQLlXPeA06dPR8cgnnvuuWCblpSZ8RJrWlJBX5f03rN58+YoR0enmyW3bIbeo86aNQvl6DnNjH8GoeV69J6Svl7o38bnc2v4vb5s2TK8X5zZs2dHPkZbklDLly9HOVo+5TOinp5/69Spg3L08/Inn3wS+dj9999/9GOjI4uIiIiIiIiIyM9OX9SIiIiIiIiIiCSEs/RpypQpwbbPxKb69eujHF1Kv379epSj3dzpsl6f8ha67ImWc3Tt2hU/dxy6FJcuOQ0vU41Dl1rTJYQVKlRAOdqRvFWrViiXmZmJcmapSzsHDhyI93NxlWTRJXx0+SVFl72Hy4jilCxZEuXo+SgdS7xHjRqFjkGEp1xVrFgR70f/hnR5Pv07n3/++ShXpEgRlDuZJtJQPiV5e/bsQbkRI0ag3EsvvYRyQ4YMQbnXX38d5XwmQYSXwKerfM3MrFChQpGP0XMbXSJPl7TT9/nPcU6l92O0JMH1XvcpvXW57LLL0PMdiZaFlilTBuW2bt2KcrRkhv58PpNmaFn3iThHHz58GOXGjh2LcnRCkBm/R61UqRLKlStXDuXoVCl6L0tfg2Zmb7/9drBNpzfGcZUn0xJnWqJG0TJin5IjOomW/v/Se1nXPWpOTg46BvHXv/412Kblo2ZmPXr0QDn6WqAtB+hnR3ovS79HMONls/QeL6pUUitqREREREREREQSQl/UiIiIiIiIiIgkhL6oERERERERERFJCGePmttvvx0dhNYsZ2VlsZ/KeK0iHcf1448/ohytT9u1axfKFS1aFOXMUnvn0LGcxKOPPhr5GK0VX7BgAcrRse3ff/89yvn0CaK1o/R12K5dO5TbvHlz5GNDhw5Fx4jTqVOnYLthw4Z4P5ql/x/z589HOfp7h+thXWgvoZONz3hcOhadngPDY6pdtmzZgnIUPZebpY5vHTZsWFqeP9xn6Eh79+5Fx3CNaAyj/xe0rwTtz2ZmlpGRgXKlSpVCOdrHzTXC3jWO2Ve45wQdUX/kfi716tVDubZt26Ic7TVD+5v8GtC+a7RPH+3tZMZHAq9btw7laE8L+jqgvVcKFiyIcmap43lnzJiB94vj89kgCu2xSD9b0P5TPmPWfe5nCVefrbDLL7888rGXX345LT9L48aN/6v9LrnkEpSrW7cuytH+RLRH4AcffIByTz/9NMqZmZ177rk4e7zRz3q0HyLtfeaDHpP2KKLHW7JkCcq5+jW5jhn1GtKKGhERERERERGRhNAXNSIiIiIiIiIiCeEsfbryyisjd6TLJelye7rsky57P3DgAMqZ8bGFdCk4HeXsWgruKlfydfPNNwfbdLmaGR+Ptnz5cpSrVq0ayl177bUoFzXK7Eg+S3vp/zF9vaYLHWn3l7/8BeXosm0z/jrYvn07ytGlx/S9Tkff+ZTMhLP79u3D+8Xp1q1b5GN0GTP9+9FzIB2VTF+DZnw5OC3ToGMQXe/1vn37omPEyc7ODrZ9RmvTZe+DBw9GufLly6Pcgw8+iHInU8nMiXb33XejHC2loyVyq1evRjlaCkvLQ8xSR+DSMpU4rnsAOnKX/o1piT99Xp8xsPR8Wrp0aZSjJQGua186S1pvu+22YLtEiRJ4PzrWm1675s2bh3J0zDotPaf3smZ8ZPzxRl9T9LNNhQoV8HPT9xwtOaatLfbs2YNy9G9Dz7tmqfcTn332Gd4vzgMPPBD5WPfu3dExXO0gwui9bIMGDVCOlnua8XH269evR7lmzZqhXJ48eSIfa9269VH/XStqREREREREREQSQl/UiIiIiIiIiIgkhLP0aeDAgcF2kSJF8EHpkrXTTjsN5egyWVp6QYU73MehS+/okrAnn3wSP3ccujyPlnj88Y9/xM+dk5ODcrRjPF0CTI9Hl+/S5dFmqSVttIwhjuv9R6dd0deBa2leGF3OSSfSmPHzDD0n0JIZV45OliMGDBgQbPuUmtDXH50mQJeS0vIaWj5F/z9OJj7lU3TS1rvvvotyq1atQjl6faPXTJ/S0XC57pAhQ/B+cVw/Ky2TpJOsaAk4Pff6TJqh5bwUfb26/o9pOW2c8PnpwgsvxPvRex16baWTwOgUUDrZyWcCJC3x9ymPTxdapjt9+nSUGzRoEH7ujh07ohy9xtESOVpSsX//fpTzmQAZLgGi5ZBxypUrF/kYPU/SqYT0/Eyn+fiUxdMWDrQslE6uc5VF7dixAx2DmDp1arA9evRovB/9zEXPlfR1v2zZMpSjk5hcr+Mj0fMWvS+PymlFjYiIiIiIiIhIQuiLGhERERERERGRhNAXNSIiIiIiIiIiCeHsUUPrpWnNsmvs15ForTut76NjwGgPBdojg9bZmaXW0NGRqkTPnj0jH6MjY8ePH49yPr8v4dPLgI51pLW8jRo1QjlXzepjjz2GjhEnXLvoU0NJ66Uff/xxlHvqqadQjvZQ6NChA8pdddVVKJd06T6n+vQ3oedA2g+H9gugfVBoDwCfHgpz5swJtidMmID3c3GNqKTXhUWLFqEc7StFz5O0V4CZWfHixVGOjhSltf2uvhv9+vVDxyDCPTtKlSqF96P9QypXroxynTt3RrkqVaqg3InoMXKi0Pu/3NxclBs1ahR+btovio7Opb8LfQ/T3mo1a9ZEOTOzzMzMYJv2wSLOP//8yMcKFSqEjkH7DfqMRSfoPbQZ71FEr9W0/1+xYsUiHwtfI49F+BxK+4+a8Z4ldCw5PR7tu7ZhwwaU+/Of/4xyZrxnyYmwdOlSlKN/P5++hPQcSO+j6euQXtNpr7ns7GyUM0u936lfv/5RM1pRIyIiIiIiIiKSEPqiRkREREREREQkIZylT64yBzoKmy6jp0v4aUkFXTpoxkcC0yVca9euRTnX7zJu3Dh0DCJc1rJz5068H106S39furysa9euKNemTRuU81maSsunfEqyjqcXX3wR5ejYdDOzJUuWoBxdtkhLz+jSSjoGkS6XNEs9H9ERfET79u0jH0v38ks6mrJ06dIot3v3bpQz46WrdPw3HWXuKkcYPnw4OkacJ554Itj2uc5UrVoV5ej7iJae0XJFurRcjt3dd9+NcrSUbuXKlShHzx1ff/11WnNmqedRes6O4yqdpSVHNEfPQfTewGecMh2tXadOHZRLR4kmHS9NNGnSJNiuXr063o+W/mRlZaHcrl27UI5eC+lI4NatW6OcGf9djjd63Zo4cSLKbdu2DT83LXtbt24dytHPt/QelZYH+4wJD5dApnM8t+s9T++haXkmvX7Q34++DszMvvnmG5Rr0KABytWtWxflXNe+qHtxragREREREREREUkIfVEjIiIiIiIiIpIQ+qJGRERERERERCQhnD1qrrnmmmCb9jEwM6tQoQLK0X4ztI6N9mSg9aV0tLGZWUZGBsrRUYO9e/fGzx2H9tigf5fbb78dP/enn36KchdddBHK0f8T2juCjlD16e1TuHDhYLtv3754P5eCBQse8zFo/Sutnad9pXz6+dCac3pM+jO6/ja0bp0I91+qWLEi3o+OaT7vvPNQrm3btihHxxbT/l0+46FPFj516WvWrEG5gQMHohztyUXRn4/2yDBLPfdNnTrV+2eK4updRs8bPv3PCPr+8Dmn0p+R5mifAlfuiy++QMeIE75+0/8zM7Ny5cqh3MaNG1Hu4osvRrlatWqlNUd7fJnxPjf0vjydaC/LmTNnotzQoUPxc9MeFPT9QXte0tera7R22JgxY1DOLLWXx/z58/F+Lq57BdoPhP5NaI8r+rw+I6TpZ2H6uZX2r3G9/mg/USLcn8enP+Py5ctRjvb6ovcI9NxBR6IXLVoU5cz4dx30d456r+uuWUREREREREQkIfRFjYiIiIiIiIhIQjhLn+gS1z59+qBcvnz52E9lZl9++SXK0VKigwcPohxdepybm4tyPkujW7VqFWyns/RpwIABkY/NmDEDHYOWMNExanS5n0/JDy0/o69rOm4tPFrySPfeey86RpxwiUK4tCpO8eLFUY4uOaVlb2+99RbK9ezZE+WuuOIKlEs6+nf2GSVO0eXC+/fvRzlahpKdnY1ydBn/vn37UM4stRz2tddew/u5uEap0r8dHQlMlx7Tpds/RxkiLZWgZaaua3VOTg46BhEuBfEp96Ali2XLlkU5Opq3Xbt2KEeXWf8a0JHAdBn9sGHD8HPTpf50zPDWrVtRjt7n0NHQPq/98Pnj1VdfxfvFadiwYeRj9O9H793pZwt6vfRpkUA/D9DfhR6vatWqkY999NFH6BhxwqUlPiXOJUuWRDl6jaOlK82bN0e5jz/+GOWeeeYZlDPjZYgnAi2joi0SDh06hJ+bjm6vUqUKytFWAPR3GTVqFMpdf/31KGdmlpmZGWxnZWUdNaMVNSIiIiIiIiIiCaEvakREREREREREEsJZ+vTKK69E7kiX8C9evBjlaGlSuruCm/El3nRJMT2ea5LL22+/jY5BhJfkrV+/Hu9Hl40tW7YM5ebOnYtytJSOLi+jS4XNeMf+4412r+/fvz/KLVq0CD83LfOj5Wx0Ohvtmk8nfPmUE4V/F7q8nujVq1fkY1dffTU6Bi05ouWKZ599Nsr5TAC49dZbUY4uAT7ttNNQzjWdjU66itO4ceNgu1OnTng/ulyX/p0nT56Mco888gjK+Uwhk2Nz1113oRwt+6BTlOhri5YK0fs2s9RyiMOHD+P9XFznGTqtb968eSiX7kmD9Jxmxqez0fJRWjLj+hmHDx+OjkG0aNEi2L7uuuvwfvQ+hrZdoJ8b6KSZ8O/l0qZNGxuEOyoAAA0DSURBVJQz49Nrjjd6X0fPfT42bdqEcvR8RXN0YiO9R/WZXBd+rfqUg8dx3TfSKXj056H3f99++y3KffLJJyhnxj/r0dd1+/btj/l4USWgWlEjIiIiIiIiIpIQ+qJGRERERERERCQh9EWNiIiIiIiIiEhCOHvU3HDDDcE2HV9lZlasWDGUoz1f6tevj3JLly5FOVqnHTUq62ho/ws6iq5bt274uePQkbErV65EOZ8xdPRvSGvs6ShT+nemddY+Y23Dvwsdfx7H1feIvjfp70DrtOlr3mdEPa3RpeMf6ehR1+hHV98TX+G+IiNHjsT70b5XderUQbnf/e53KFegQAGU8/k/llS0zt2M9wN78cUXUY72lbryyitRjtaI+/R9CtenjxgxAu8Xx/XapudUeq6k5zWa83m/0fHBtA8aPZ6r99XmzZvRMeJ07do12KY9zcx4/y76OqD9p+i9LO0XVa1aNZQz4+Pi6RjkdKI9Leh4XNoP0UflypVRjv6d6RhpOh7a5z21evXqYHvDhg14PxdXzw96jaPnP/q+9PncSp111lkoR/uqpGMUO+3HRcyfPz/Y3rp1K96Pnoto/8Lwud2F9pChPWlony8z/jvT+/eoXlpaUSMiIiIiIiIikhD6okZEREREREREJCGcpU8TJ05EB5k5cybKHTp0iP1UxsffFSpUCOXoEmU6xo8ua/MZpVeuXLlg+5ZbbsH7xWnevHnkY3Q075w5c1COllmleym4GS+5oyVAtDTvgQceiHysd+/e6BhxMjMzg226RN2Ml4DRUaGlS5fGz008//zzKPdrGR1MX88+o8QpOiKSLnedNGkSyu3YsQPlPv/8c5Rr0qQJypmlLkO/9tpr8X4uXbp0iXyMlhLt2bMH5eh59+d4XdElwHTpMV3+67pmTpkyBR2DqFChwn+1H71+1K5dG+WqVq2Kcn/4wx9QjpZ7/hrQEjo6bnz06NH4uXNyctL63PTeqVatWihHS2vovayZWXZ2drBNf3+iUqVKkY/5fG4g6P0TPZf73I8VLlwY5ej9GC0pct3L0jLAOOER8vRcb2ZWsGBBlKOvZ/o+Cn/ecqElM/3790c5Mz6W+kSg9yb0M/WWLVvwc9P7HXrev+qqq1DunXfeQbnrr78e5eg53yy1fCrq85pW1IiIiIiIiIiIJIS+qBERERERERERSQh9USMiIiIiIiIikhDOHjWvv/565I6rVq1CT0D7ImzatAnlaN8Qn1GNdJzehRdeiHK0v86CBQsiH/OplY7zyiuvBNvbt29P23H/z5IlS1BuzZo1KNeqVSuU69evH8rR14wZr0dNKle/nLCpU6fiY9JRsHTEJq0vpfXX9BzjM6ox3OeB1jwTY8eOjXyMjrKno5fpeSgjIwPlvvzyS5Qz4/05aL+Z3bt3o5yr9vvyyy9Hx4jTpk2bYNvnfHH//fejHK3Ff/TRR1GOnhOqV6+OcnLsHnroIZSj51Q6Yjc3Nxfl6PvNp+dRuKfB4cOH8X4ujRs3jnzs4MGD6Bj0b0Lfl/Q8SfuQmLlHyYfRnog1atRAOdc1mPaXI8LXvmbNmuH9GjVqhHL0fbRw4UKUo70x6fje6667DuXM+H3C8UZ7lT3xxBMot3btWvzcGzduRDl6vqJ9h+jnTHqPSu+N07Xf0bjOh/ScSv8utD8S7ZtIXwdm/HMNHSdevHhxlHP9baJ6gGpFjYiIiIiIiIhIQuiLGhERERERERGRhHCWPoVHUfmME6MlC3T5IB1p98UXX6AcXSaWN29elDMz69ixI8rRJax0aSpBlyQOHjwY5V544QX83HQZ69VXX41yK1euRDm6RC889tqFvrbMUpdIP/zww3g/F9d7hY6RpMsv6dg9ymdUI10OTnP0vX7WWWdFPrZr1y50DGLatGnB9uTJk/F+dCQwXX7Zs2dPlKP/dz7nSklF379mZosWLUK5O++8E+XouEl6TV+6dCnK+YyvDJ9PR44cifeL47oWp3vcOT2n0r9z/vz5Uc7nmPQcQ0tIXX9fn+upy1133RVs+7ymZsyYgXL0fFqzZk2UoyPh69Wrh3K01MnM7LzzzkM5WhKQTrRcbPz48Sj33HPP4eceNGgQytFSHFpyTMtD6D2MTxli+DNBus6prnuFcCm5Cz1P0pHy9G/i85qnvwtFfxfXPVY6y/PD7TF8PgusWLEC5WgZE71GNGjQAOXo35mW7ZvxEe/0/jjqGqwVNSIiIiIiIiIiCaEvakREREREREREEsJZ+vTRRx+hg+zcuRPlaNmKmdmePXtQji4zpNM56HLEKlWqoJzPMrnwcuZ77rkH7xfHtbSTLgFevnw5ytHu+nT5NJ1IY8aXKdOO7iVKlEA517LnN954Ax3D52fxWeJKJ14VLFgQ5c4++2yUo6/7oUOHolypUqVQTqLRZax0Ah/tsJ+Tk4Ny27ZtQ7kLLrgA5czMWrZsGWzTc3aczp07Rz5Gy+TotAN6bf05Ss/o+ZS+rujP6JrCSO9JiHA5t095Jp3+4yqnDKtTpw7KDRw4EOVOROnKiULv12gpNC3/NuNliIcOHUI5Wm5H/39r1aqFcnTqqZnZ9OnTg21ahkS4zql0EhMtfaNlVrQk1Wd6Fz130DJ1eo5xlUr6fC5zCZfn0zJKM/7ZjLbKoPe89LpF32/Dhw9HOTO/99zxRj8fff755yhHP6Ob8XtA2rKCfr6ln/Voi45TTuFrYMKvr6j3glbUiIiIiIiIiIgkhL6oERERERERERFJCH1RIyIiIiIiIiKSEM4eNa4Rd7Q2cvHixShHa/bpqEkf1atXR7lixYqhHB2V5urT8re//Q0dg+jRo0ewTceJmfEa3WXLlqEcHW9Yt25dlHvsscdQzme0PO3VklTPPvssyo0ZMwYfk46HpLWotP6ajtOjtf0+owbDx6S/P7Fu3brIx+g5cObMmShH32/58uVDufBIzzh0ZGLz5s1RjvZGWrJkSeRjt9xyCzpGnBYtWgTb9NphZtatWzeUo/9vq1atQjn6e/tcG+TYdO3aFeVoDxbaL4Dm6DmVnsvNUu93fEZpu7h6BtAeWrSvFO1jRP8mtBeEmVn58uVRjvbxoH2+XD2yfHpyxKlRo0awTc/1ZmYXXXQRytHR5PS1QK/BnTp1QrmmTZuinJlZxYoVcfZ4or2Y7r//fpTbvXs3fm7ay432qqL3OvR3pveyPr19wufTdN6juvqM0nMq/Qx84MABlKO9aw4fPoxyPs/dpk0blKOfW12fq6N6cWpFjYiIiIiIiIhIQuiLGhERERERERGRhHCWPt13333B9tatW/FB6Xg0OqqOLmei4z/pUv+GDRuinFnq0k0XuvS4VatW+Lnj0GV3Tz31FMpNnjwZP3eTJk1wlqAjJ+myNjr2ee7cuShnlro8cMKECXg/F9eyazqum+ZoiRBdpkmX75uZFShQAOVoCSQ9F7mW+tOR88Trr78ebOfm5uL9aCkC/fu1b98e5cqUKYNyJ9NI4HTzKeedN28eyt12220oR68z9Nyxfv16lPMRHqebnZ2dtuO6SizoUnL6d6HjOl3l0P8tWqZOfxd6/+S6juzZswcdI064hIze55iZzZ8/H+XoGF1aXl25cmWUa9SoEcr5lCvS8h+fcdPpQksl6L3nm2++iZ/7oYceQrk5c+agHC1pc43MDqP3qCtWrEA5s9RrzjPPPIP3c3Hdo9LzHy0bpOdJem2l5zQz/rvQezZ6H+16X9L3D7Fjx45g22fMNP2cTsvUVq9ejXKFCxdGOfp9Az1PmvGx3j6vr6PRihoRERERERERkYTQFzUiIiIiIiIiIgmhL2pERERERERERBLC2aNmy5Yt6CA0N2PGDPZTGR9VS8eo0T4ZFSpUQDk6xrlmzZooZ5baV6VPnz54vziufhS0tpH+f9D6Q1r7SPsOmZllZGSgHK3Bpj+jq29OunrUFClSJNg+/fTT8X70dyhZsiTK0XraSpUqoZxPLbkcG9p7iNYG035bQ4cORbkePXqgHP35zMyKFy8ebHfv3h3v53LxxRdHPkZH+NK/Hb22pnuUvRnvk0H7E9Hzrmt85ezZs9ExiGLFigXb9Npx5H4u9NpFR9nTHnI+fQV+6ej9H80NGjQIP/fmzZtRbu/evShHe5HQ8cz0/ebTkybcB+Xdd9/F+8W59957Ix+bMmUKOgbtDUN7w9Hj0b5wZvzejfaLotcb18/ocz11oaPhj0TPk/TvTM/PtP9euEeay+DBg1HOzCwrKwtnjzfa/4d+dqT3MGap/XFc6DVuzZo1KFe/fn2Uy8zMRDmfz63hc0JUT7ST54ouIiIiIiIiIpJw+qJGRERERERERCQhnKVPIiIiIiIiIiJy/GhFjYiIiIiIiIhIQuiLGhERERERERGRhNAXNSIiIiIiIiIiCaEvakREREREREREEkJf1IiIiIiIiIiIJIS+qBERERERERERSYj/AcEO1DpdDP58AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x1440 with 10 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 10 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoWSKKDT2cl9"
      },
      "outputs": [],
      "source": [
        "# pick any image\n",
        "any_image = X_test_noisy[10]\n",
        "# run it though the autoencoder\n",
        "output_any_image = sess.run(output_layer,\n",
        "                   feed_dict={input_layer:[any_image]})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kbkbHJna2cll"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}